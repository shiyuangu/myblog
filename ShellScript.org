#+BLOG: wordpress
#+POSTID: 106
-----------------------
#+TITLE: ShellScript
#+DATE: <2014-12-23 Tue>
#+CATEGORY: 
-----------------------
* Flow Control 
#+BEGIN_SRC shell
for i in {1..12};do
   scp -i ~/tmp/tmp_pem hadoop@ec2host.com://path/to/file_${i}.Rda .
done
# or in one line
for i in {1..12}; do scp -i /tmp/tmp_pem hadoop@ec2host.com://path/to/file1_${i}.Rda . ;scp -i /tmp/tmp_pem hadoop@ec2host.com://path/to/file1_${i}_train.Rda . ; scp -i /tmp/tmp_pem hadoop@ec2host.com://path/to/file2_${i}.Rda . ; done
#+END_SRC

* Piping
+ Piping with stdin redirection. Without the stdin redirection, emacs complains the stdin is not tty. The "$@" is a [[http://unixhelp.ed.ac.uk/scrpt/scrpt2.2.2.html][Special Shell Variables]] which is a string containing all arguments to the shell 
  #+BEGIN_SRC shell
  ls prod_JP*|xargs zsh -c 'emacs "$@"</dev/tty'
<<<<<<< variant A
  #+END_SRC 
>>>>>>> variant B
  #+END_SRC
+ execute user function on /find/
#+BEGIN_SRC shell
#example 1
export -f myfunc #export the function; otherwise, the subshell won't know it
find . -exec bash -c 'myfunc "$0"' {} \; #only shell know how to execute the user function; {} will be substitute by the filename  and further substitute $0;   
#example 2
find . -type \*csv --exec sh -c '"$0" "$@" &' gzip --fast {} \; # $0 is gzip and $@ are all other parameters which in this case are "--fast {}" with {} substitute by filename from find.  

#+END_SRC
####### Ancestor
  #+END_SRC
======= end
* Utilities
** /find/ (Cf. [fn:2]):
+ -exec 
  #+BEGIN_SRC shell
    #The following commands do the same things: 
    find / -name core -exec /bin/rm -f '{}' \;
    find / -name core -exec /bin/rm -f '{}' +
    find / -name core | xargs /bin/rm -f
    find . -maxdepth 1 -type d  -user o643799 -exec bash -c 'cd "$0"; rm -R -- */; rm -rf el_merge_monthly*' {} \;
 
##Note the -- (thanks for adding that, Stephane) which separates options from arguments and allows one to remove entries starting with a hyphen - otherwise after expansion by the shell the entry name would be interpreted as an option by rm (the same holds for many other command line utilities).
http://unix.stackexchange.com/questions/68846/how-do-i-remove-all-sub-directories-from-within-a-directory
  #+END_SRC
    - There are two forms of -exec;. The form ‑exec {} \; (The semicolon must be quoted from the shell, so find can see it!)  With the -exec{} \; the word “{}” will expand out to the name of the found file, the semicolon means the command runs for each match file;. An alternate of the semicolon is  a plus-sign +. This form runs the command once for all files    (xargs[fn:4],  which together with "-L" options, gives more flexibility of how to group the arguments into sets)[fn:3] [fn:2]
    + To handle exotic filenames(which contain spaces or newlines), use the form "find .. -print0|xargs -0 ..."

+ Gotcha: When no action is given, "-print" is assumed and grouping is perform. This could messed up the boolean operation precedence and give surprising results. See [fn:2].  
** /tar/
+ Archive and gzip a whole directory:  
#+BEGIN_SRC shell
  tar czvf ShiyuanGu.tar.gz ShiyuanGu  
#+END_SRC
+ Extract and uncompress: 
#+BEGIN_SRC shell
  tar xzvf ShiyuanGu.tar.gz ShiyuanGu  
#+END_SRC
** /rsync/
+ Rsync between remote and local through ssh 
#+BEGIN_SRC shell 
rsync -avzhe ssh --progress shiyuang@shiyuang.desktop.amazon.com://path/to/dir .
rsync -avzhe "ssh -i /full/path/to/pem" --progress localdir user@ec2host.amazonaws.com://mnt/
rsync -avzhe "ssh" --progress  cambia/ algorithm:cambia/ ## assume we have set up the host alias and id file in .ssh/config
#+END_SRC
+ exclude subfolder
#+BEGIN_SRC shell
rsync -avhze "ssh" time-series-classification/ --exclude ".git" sgu@7070:time-series-classification
#+END_SRC
-a: archive
-v: verbose
-z: compress file data during transfer
-h: human readable info
-e ssh: connect through ssh(Use full path in -i) 
  
** /screen/
+ Name session: screen -S myname
+ Scroll back: C-a-Esc to enter copy mode, then navigate in a vi-like manner [[http://www.linuxscrew.com/2008/11/14/faq-how-to-scrollback-in-gnu-screen/]]:
#+BEGIN_SRC 
h -    Move the cursor left by one character
j -    Move the cursor down by one line
k -    Move the cursor up by one line
l -    Move the cursor right by one character
0 -    Move to the beginning of the current line
$ -    Move to the end of the current line.
G -    Moves to the specified line
       (defaults to the end of the buffer).
C-u -  Scrolls a half page up.
C-b -  Scrolls a full page up.
C-d -  Scrolls a half page down.
C-f -  Scrolls the full page down.
#+END_SRC
** /sed/ 
*** Features 
 + Make only one pass over the inputs and hence more efficient. 
 + Ability to filter text in a pipeline
  
*** Synopsis: 
    #+BEGIN_SRC shell
      sed [OPTION]... {script} [input-file]
    #+END_SRC
    - The script is actually the first non-option parameter, which sed specially considers a script and not an input file if (and only if) none of the other options specifies a script to be executed, that is if neither of the -e and -f options is specified. `man sed` calls it {script-only-if-no-other-script}. 

    - When multiple -e, -f are givens, the script is understood to mean the in-order catenation [[https://www.gnu.org/software/sed/manual/sed.html#sed-Programs][Cf. here]]
    - /sed/ maintains two spaces, the active pattern space, and the hold space. Both are initially empty. /sed/ processes the input line by line. The input  can be a file, a list of files or /stdin/, denoted by the character -. /sed/ starts each cycle by reading in the line, removing any trailing newline and placing it in the pattern space. Then the script commands are executed. When all commands in the script are finished, the contents of the pattern space are printed out to the output stream, adding back the trailing newline if it was removed(well, some little nasty thing happens here Cf. [[https://www.gnu.org/software/sed/manual/sed.html#fn-3][sed manual footnote]]). The pattern space starts from fresh before each cycle starts(except for special commands, like D). The hold space, on the other hand, keeps its data between cycles (Cf. [[https://www.gnu.org/software/sed/manual/sed.html#Execution-Cycle][How sed works: Execution Cycle]])
    - When the input is a list of files, by default, /sed/ considers the files a single continuous long stream. GNU /sed/ extension has a option `-s` allows user to consider them as separate files, and line numbers are relative to the start of each file (the catch for `-s` is that range address cannot span several files).  For example, suppose sed-test-1.in and sed-test-2.in has two lines of "abcde". The first command below only replaces the first line in first input file sed-test-1.in while the second command replaces the first line in each input file as well as the input from /stdin/ 
      #+BEGIN_SRC shell
         echo "abcd"|sed -e "1 y/a/b/" sed-test-1.in sed-test-2.in -  
         echo "abcd"|sed -s -e "1 y/a/b/" sed-test-1.in sed-test-2.in -  
      #+END_SRC

*** Examples 
****  Centering Lines with /sed/. 
In GNU sed manual, this script(https://www.gnu.org/software/sed/manual/sed.html#Centering-lines) is used to demonstrate how to center each line with sed. But this script is *wrong* and *dangerous!*. If a line is longer than 80 characters, the line will be silently truncated.  
     #+BEGIN_SRC shell
	 #!/usr/bin/sed -f
	 # Generate 80 spaces in the hold space
     # Note that hold space keeps its data between cycles,but we only need to generate the spaces once. 
     # The 1 is the address matches only the first line. 
	 1 {
     x   #swap pattern space with hold space; since s operates on pattern space only. 
     s/^$/          /   #Replace empty line with 10 white spaces;  
     s/^.*$/&&&&&&&&/   # ^.*$ matches the previous inserted 10 white spaces; The & means the whole match. So we have 80 white spaces;  
     x   # swap pattern space with hold space. Now we have 80 spaces in the hold space. In the pattern space, we have the current line. 
	 }

     # del leading and trailing spaces
     # The y command transliterate characters. 
     # Note that the y command, different from s,  allows no comments on the same line  
	 y/\t/ /
	 s/^ *// # delete all leading spaces  
	 s/ *$// # delete all trailing spaces

     #The G command append a newline to the contents of the pattern space, 
     #and then append the contents of the hold space to that of the pattern space. 
	 G      

	 # keep first 81 chars (80 + a newline)
	 # Note that . in sed matches newline. This is different from elisp or python
	 # CAUTION: This command is dangerous, if the line is longer than 80 characters, we will lose anything after the 80th characters!
	 s/^\(.\{81\}\).*$/\1/

	 # \2 matches half of the spaces, which are moved to the beginning
	 # The expression \(.*\)\2 captures necessary amount of spaces to fill in front, and divide the spaces equally into two parts. 
     # Grouping and subexpression matching allows us to do arithmetics. 
	 s/^\(.*\)\n\(.*\)\2/\2\1/
     #+END_SRC
**** Replace leading spaces with tabs. 
Sometimes we need to change indentation style, for example, replace every leading four spaces with one tab. The following one-liner will do the work. Note the use of label, conditional jump command t and grouping. The command t jumps to the label only  when the substitution succeeds. The command t and the label forms an implicit loop where each iteration replaces a four spaces with a tab. For the meanings of `{}` and `+`, refer to the `find` utility  [[http://shiyuangu.com/2014/08/13/linux-utility-programs/][here]] .
     #+BEGIN_SRC 
         find . -iname "*.ion" -exec sed -i ':l s/^\(\t*\) \{4\}/\1\t/; t l' {} +    
     #+END_SRC
     
*** Gotcha: 
**** The s command and the g flags. 
The command 's/Hello/HelloWorld/' only replace the first match of each line. To replace all matches, use the g flag, 's/Hello/HelloWorld/g'. 
**** Word boundary
Sometimes we think in terms of word and want the match for the whole word. In this case, use the world boundary "\b" 
** /cut/
 + Delete the third field with a common as field separator 
  #+BEGIN_SRC shell
  cut --complement -d, -f3 adult.data > income_train_data.csv
  #+END_SRC
** /column/ 
  + The following one-liner is taken from [[https://chrisjean.com/2011/06/17/view-csv-data-from-the-command-line/][this post]]. It allows us to display s csv(comma-separated-value) file in a nice format using command lines
   #+BEGIN_SRC shell 
     cat file.csv | sed -e 's/,,/, ,/g' | column -s, -t | less -#5 -N -S
   #+END_SRC
   The sed command is used to handle the corner case of empty field; the 'g' means replacing all matches not just the first;  the `-s` in the `column` command is to specify delimiters; `-t` creates a table for pretty print; `-#` in the `less command `specifies the number of positions to scroll using right/leftarrow key; `-N` displays the line number and `-S` causes the line to be chopped rather than folded ( that is , `M-x toggle-truncate-lines` in Emacs). In case of  tab separated file with missing field, we can replace tab with comma first, and then fill in the missing field with space, 
   #+BEGIN_SRC shell
   cat file.txt|sed -e 's/\t/,/g;s/,,/, ,/g'|column -s, -t|less -#5 -S
   #+END_SRC
   The sed command 's/\t/,/g' replace tab with comma and 's/,,/, ,/g' fills in the missing field with a space. Note that without the fill-in step, the alignment is wrong. 
** /awk/
<<<<<<< variant A
A good tutorial: http://www.grymoire.com/Unix/Awk.html#uh-1
>>>>>>> variant B
A good tutorial: http://www.grymoire.com/Unix/Awk.html#uh-1
`man awk` is also quite complete about the syntax
####### Ancestor
======= end
*** Randomly Sample 1/1000 row. 
#+BEGIN_SRC bash
awk 'BEGIN {srand()} !/^$/ { if (rand() <= .001) print $0}' infile.txt> outfile.txt 
awk 'BEGIN {srand()} !/^$/ { if (rand() <= .01 || FNR==1) print $0}' infile.txt> outfile.txt #include header. 
#+END_SRC
*** Exact a field and numeric comparison
#+BEGIN_SRC bash
## The following awk command extracts the lines with pval less than 0.05 from a csv file
## Sample line: 20150204,21,R,cp, All, 1, NTrig, pval,.04
## -F specifies field separator $0 is the whole line, $8,$9 is the eighth and ninth field. 
awk -F, '$8==" pval" && $9<0.05 {print $0}' inputfile.csv
#+END_SRC
*** Concatenate files with same header
#+BEGIN_SRC bash
## concatenate csv files with the header stripped-off except the first file. 
## FNR==1 && NR!=1: match the first line of a file except it's also the first line across all files(NR==1)
## getline: skip the line. 
## 1{print}: print everything except the lines previous skipped  
> awk '
FNR==1 && NR!=1 {getline;} 
1{print}
' input-blob*.csv > input-all.csv

## A more sophisticated example: the header spreads multiple line. 
> awk '
FNR==1 && NR!=1 {while (/^<header>/) getline;}  #skip the lines started with the <header> tags
1{print}
' input-blob*.csv > input-all.csv
#+END_SRC
*** replace the commas inside quotes
#+BEGIN_SRC shell
#### -v key=values change the program variables; OFS is the output field separator; without -v OFS='"', the double quotes would be gone in the output.  
 awk -F'"' -v OFS='"' '{ for (i=2; i<=NF; i+=2) gsub(",", "", $i) } 1' tmp.txt
#+END_SRC
** /paste/
*** Concatenate files columnwise  
#+BEGIN_SRC zsh
## The following command combines three files by columns and select the 1st, 2nd, 4th field. 
### "-d," inserts comma to separate between files so that the result is also a csv file
### "-F," in awk specifies the field delimiter
### "-v OFS=','" inserts comma between fields on output
paste -d, file1.csv, file2.csv, file2.csv|awk -F, -v OFS=',' '{print $1,$2, $4}'
#+END_SRC
<<<<<<< variant A
** /gs/
*** concatenate multiple ps file into one pdf and adjust the size of paper
#+BEGIN_SRC bash
gs -dBATCH -dNOPAUSE -sOutputFile=dot-test-all.pdf -sDEVICE=pdfwrite -c "<< /PageSize [3800 600]  >> setpagedevice"  -f dot-test*.ps
#+END_SRC
** /sort/
*** sort by field and character
*CAUTION: characters in a field are counted from the beginning of the preceding whitespace* 
#+BEGIN_SRC bash
# sort the following the 4th character in the 10th field. Caution: the both the field and character origin 1; but the characters in a field are counted from the beginning of the preceding whitespace; in the following line 10.4,10.4 is the KEYDEF, the first 10.4 means "the key starts from the 4th character in the 10th field", the second 10.4 is the ending location. The ending and starting location are the same and hence the key is only one character. (Cf. `man sort`)
ls -ltr|cat -n|sort -k10.4,10.4   
#+END_SRC
*** sort by multiple keys
#+BEGIN_SRC bash
#the first key is the 4th character in the 10th field, the second key contains the 2nd and 3rd characters of the 10th field.
ls -ltr|cat -n|sort -k10.4,10.4 -k10.2,10.3 
#+END_SRC
####### Ancestor
======= end

* Package Management
** list all installed package 
apt list --installed (for ubuntu 14.04)
** List all files installed by a package 
dpkg-query -L openjdk-8-jdk
** switch version
sudo update-alternatives --config javac
which lists all alternatives and prompts which version to switch to 
* Footnotes

[fn:1] [[http://en.wikipedia.org/wiki/POSIX][WIKI-POSIX]]

[fn:2] [[http://content.hccfl.edu/pollock/unix/findcmd.htm][A Unix/Linux find command Tutorial]]

[fn:3] man find

[fn:4] man xargs


 
